{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#kevin frankola\n",
    "\n",
    "#the intention is to put both the images from training (primary and \n",
    "#secondary) and test into .pkl files so that they can be used for the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bring in libraries and stuff\n",
    "#going to import cPickle and decide later\n",
    "import _pickle as cpkl\n",
    "import pickle as pkl\n",
    "from PIL import Image\n",
    "import os, os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the intention is to build 2 pickles\n",
    "#one will be the train dataset primary images and secondary images\n",
    "#training pickle dataset will be a list object. every element in the\n",
    "#list object will be a dictionary where the first image is a key (this is the primary image)\n",
    "#and then the value will be the secondary image (the answer to the key) this association must\n",
    "#be maintained throughout they system\n",
    "\n",
    "#one will be the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#so the first image list is going to be called: test_image_list\n",
    "#the next layer down (each element of the list) is going to be a dictionary\n",
    "#that dictionary is going to have 1 key and 1 value\n",
    "\n",
    "#so:---- a list of dictionaries of one element each\n",
    "\n",
    "\n",
    "\n",
    "#need to come up with way to iterate and match the ends of the strings before the _mask.tif\n",
    "#so as stated earlier the plan is to use the primary as the keys and\n",
    "#the secondary as the values. so f = key and g = val. \n",
    "\n",
    "#for f in os dir\n",
    "#if f doesn't end with mask.tif then make the comparison\n",
    "#otherwise skip f for that iteration because we want to keep f as the key\n",
    "\n",
    "import copy\n",
    "\n",
    "train_image_list = []\n",
    "train_path = '/home/ec2-user/Notebooks/datasets_for_projects/train'\n",
    "outerloop_count = 0\n",
    "innerloop_count = 0\n",
    "for f in os.listdir(train_path):\n",
    "    #sub_train_image_list = []\n",
    "    if not f.endswith('mask.tif'):\n",
    "        for g in os.listdir(train_path):\n",
    "            gString = copy.deepcopy(g)\n",
    "            fString = copy.deepcopy(f)\n",
    "            if gString.endswith('mask.tif') and gString.replace('_mask', '')==fString:\n",
    "                #the -4 indicates that i am slicing the .tif off of the back if the\n",
    "                #file name that is being passed as the key for the dictionary\n",
    "                \n",
    "                dictNamef = str.join('', ('subDict',f))\n",
    "                dictNameg = str.join('', ('subDcit',g))\n",
    "                #need to copy the strings so they literal can be used for the dict keys\n",
    "                fStringCopy = copy.deepcopy(dictNamef)\n",
    "                fStringCopy = fStringCopy[0:-4]\n",
    "                gStringCopy = copy.deepcopy(dictNameg)\n",
    "                gStringCopy = gStringCopy[0:-4]\n",
    "                \n",
    "                \n",
    "                with Image.open(os.path.join(train_path, f)) as imagef:\n",
    "                    fStringCopy = {\n",
    "                    'pixels': imagef.tobytes(),\n",
    "                    'size': imagef.size,\n",
    "                    'mode': imagef.mode\n",
    "                }\n",
    "                \n",
    "                with Image.open(os.path.join(train_path, g)) as imageg:\n",
    "                    gStringCopy = {\n",
    "                    'pixels': imageg.tobytes(),\n",
    "                    'size': imageg.size,\n",
    "                    'mode': imageg.mode\n",
    "                }\n",
    "                \n",
    "                imageList = []\n",
    "                imageList.append(fStringCopy)\n",
    "                imageList.append(gStringCopy)\n",
    "                train_image_list.append(imageList)\n",
    "                \n",
    "                break\n",
    "            innerloop_count=innerloop_count+1\n",
    "            \n",
    "            \n",
    "    outerloop_count=outerloop_count+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/kevin/Datasets/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-aaea65d42b48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtrain_image_list_primary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtrain_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'/home/kevin/Datasets/train'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mask.tif'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/kevin/Datasets/train'"
     ]
    }
   ],
   "source": [
    "#first list is primary images from the training set\n",
    "train_image_list_primary = []\n",
    "train_path = '/home/kevin/Datasets/train'\n",
    "for f in os.listdir(train_path):\n",
    "    if not f.endswith('mask.tif'):\n",
    "        continue\n",
    "    with Image.open(os.path.join(train_path, f)) as image:\n",
    "        imageDict = {\n",
    "            'pixels': image.tobytes(),\n",
    "            'size': image.size,\n",
    "            'mode': image.mode,\n",
    "        }\n",
    "        train_image_list_primary.append(imageDict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#second list is the secondary images from the training set\n",
    "train_image_list_secondary = []\n",
    "#note train_path is the same so no need to redefine\n",
    "for f in os.listdir(train_path):\n",
    "    if f.endswith('mask.tif'):\n",
    "        with Image.open(os.path.join(train_path, f)) as image:\n",
    "            imageDict = {\n",
    "                'pixels': image.tobytes(),\n",
    "                'size': image.size,\n",
    "                'mode': image.mode\n",
    "            }\n",
    "            train_image_list_secondary.append(imageDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#third list will be the test images \n",
    "test_image_list = []\n",
    "test_path = '/home/kevin/Datasets/test'\n",
    "for f in os.listdir(test_path):\n",
    "    if not f.endswith('.tif'):\n",
    "        continue\n",
    "    with Image.open(os.path.join(test_path, f)) as image:\n",
    "        imageDict = {\n",
    "            'pixels': image.tobytes(),\n",
    "            'size': image.size,\n",
    "            'mode': image.mode,\n",
    "        }\n",
    "        test_image_list.append(imageDict)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#now that we have lists with dictionaries conaining all the data, \n",
    "#we are ready to pickle the lists since they don't contain any of the\n",
    "#images themselves it should go smoothly\n",
    "\n",
    "with open('training_P.pkl', 'wb') as f1:\n",
    "    cpkl.dump(train_image_list_primary, f1)\n",
    "    f1.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now onto training secondary images:\n",
    "\n",
    "with open('training_S.pkl', 'wb') as f2:\n",
    "    cpkl.dump(train_image_list_secondary, f2)\n",
    "    f2.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lastly lets pickle the testing set of images:\n",
    "\n",
    "with open('testing.pkl', 'wb') as f3:\n",
    "    cpkl.dump(test_image_list, f3)\n",
    "    f3.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('training2.pkl', 'wb') as f4:\n",
    "    cpkl.dump(train_image_list, f4)\n",
    "    f4.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all of the 3 image sets are now all pre-processed and\n",
    "#pickeled into 3 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(os.path.isdir('/home/ec2-user/Notebooks/datasets_for_projects/train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
