{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#kevin frankola\n",
    "\n",
    "#the intention is to put both the images from training (primary and \n",
    "#secondary) and test into .pkl files so that they can be used for the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bring in libraries and stuff\n",
    "#going to import cPickle and decide later\n",
    "import _pickle as cpkl\n",
    "import pickle as pkl\n",
    "from PIL import Image\n",
    "import os, os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the intention is to build 3 pickles\n",
    "#one will be the train dataset primary images\n",
    "#one will be the train dataset secondary images\n",
    "#one will be the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#first list is primary images from the training set\n",
    "train_image_list_primary = []\n",
    "train_path = '/home/kevin/Datasets/train'\n",
    "for f in os.listdir(train_path):\n",
    "    if not f.endswith('mask.tif'):\n",
    "        continue\n",
    "    with Image.open(os.path.join(train_path, f)) as image:\n",
    "        imageDict = {\n",
    "            'pixels': image.tobytes(),\n",
    "            'size': image.size,\n",
    "            'mode': image.mode,\n",
    "        }\n",
    "        train_image_list_primary.append(imageDict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#second list is the secondary images from the training set\n",
    "train_image_list_secondary = []\n",
    "#note train_path is the same so no need to redefine\n",
    "for f in os.listdir(train_path):\n",
    "    if f.endswith('mask.tif'):\n",
    "        with Image.open(os.path.join(train_path, f)) as image:\n",
    "            imageDict = {\n",
    "                'pixels': image.tobytes(),\n",
    "                'size': image.size,\n",
    "                'mode': image.mode\n",
    "            }\n",
    "            train_image_list_secondary.append(imageDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#third list will be the test images \n",
    "test_image_list = []\n",
    "test_path = '/home/kevin/Datasets/test'\n",
    "for f in os.listdir(test_path):\n",
    "    if not f.endswith('.tif'):\n",
    "        continue\n",
    "    with Image.open(os.path.join(test_path, f)) as image:\n",
    "        imageDict = {\n",
    "            'pixels': image.tobytes(),\n",
    "            'size': image.size,\n",
    "            'mode': image.mode,\n",
    "        }\n",
    "        test_image_list.append(imageDict)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#now that we have lists with dictionaries conaining all the data, \n",
    "#we are ready to pickle the lists since they don't contain any of the\n",
    "#images themselves it should go smoothly\n",
    "\n",
    "with open('training_P.pkl', 'wb') as f1:\n",
    "    cpkl.dump(train_image_list_primary, f1)\n",
    "    f1.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now onto training secondary images:\n",
    "\n",
    "with open('training_S.pkl', 'wb') as f2:\n",
    "    cpkl.dump(train_image_list_secondary, f2)\n",
    "    f2.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lastly lets pickle the testing set of images:\n",
    "\n",
    "with open('testing.pkl', 'wb') as f3:\n",
    "    cpkl.dump(test_image_list, f3)\n",
    "    f3.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all of the 3 image sets are now all pre-processed and\n",
    "#pickeled into 3 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
